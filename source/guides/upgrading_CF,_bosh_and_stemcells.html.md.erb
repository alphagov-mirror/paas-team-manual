# Upgrading CF, BOSH and stemcells

##Â Before Upgrading

* Separate the upgrade of Cloud Foundry and stemcells from the upgrade of Bosh. Upgrades can cause problems and our experience is that it is difficult to be certain about the cause of those problems if multiple things have changed.
* Establish the correct version to upgrade to. This will usually be the latest stable release, or the one before it, subject to review. The main driver for not always picking the latest release is to avoid the bad releases which CF produce from time to time. An alternative strategy may be to pick a release at least one week old, thereby giving Pivotal time to flag and pull bad releases before we plough ahead with them. Kick-off is an appropriate place for this review.
* Check [cf-deployment releases documentation](https://github.com/cloudfoundry/cf-deployment/releases) before upgrading to a particular version. There have been releases that became inappropriate for production usage.
* Use `git diff` or GitHub compare in the `cf-deployment` repo to see example changes to the manifest. For example, to see differences between v1.0.0 and v1.14.0:

  ```
  git diff v1.0.0...v1.14.0 cf-deployment.yml
  ```

  We also use a number of upstream ops files, so you will want to `diff` them too. See the manifest generation script for which ones get used.

* Read the documentation for every version of every release changed. It will save you time and pain in the long run.
* Update the cf-smoke-tests resource in the pipeline to use a new branch of our fork that has the latest changes from upstream master.
* Update the cf-acceptance-tests resource in the pipeline to use an upstream `cfX.Y` branch matching the cf-deployment version.

## Doing the upgrade

You should test the upgrade changeset:

* From a fully deployed master with Datadog enabled, equivalent to the change that will happen in
  in production.
* Deploying a fresh CF, which is something we frequently do in our
  development environments after the autodelete-cloudfoundry pipeline
  runs overnight.
* Confirm that [rotating credentials](/team/rotating_credentials/) still
  works and doesn't cause additional downtime during deployments.


### Buildpacks

We have to a give at least a week's notice to tenants about the buildpack upgrades, so prepare the version changes separately from the CF component upgrades.

Buildpack upgrades are typically done as a separate story. You should upgrade the buildpacks to at least the versions included in the cf-deployment version currently deployed.

## Notify the tenants

Send an email to users following [the upgrade template](/team/notifying_tenants/#cf-upgrade).

## Problems encountered previously

### Datadog

Our dev environments typically don't have Datadog enabled, so changes relating to our Datadog monitors tend to get missed. Real examples include: process checks failing because the search string used to check them is no longer valid; and manifest updates being missed because the manifest stubs for Datadog tend to be in a different location in the repository, as they are shared across all deployed jobs. The recommendation is to have Datadog enabled while working on an upgrade story and check for triggered monitors.

### DNS name resolution.
We encountered a wide variety of acceptance and smoke test failures which were intermittent. This was due to DNS health check failures. Consul uses these health checks to validate the consistency of the DNS records it serves, and will expire DNS records where the health check has failed.

The root cause was failure to remove the `consul.agent.services` property for Diego components in the CloudFoundry manifest. [Diego release notes for version 1452](https://github.com/cloudfoundry-incubator/diego-release/releases/tag/v0.1452.0) did state these had to be removed, as Diego components now use the Locket library to configure its DNS health checks.

The solution is to read the documentation on every release you are passing, for every component you are upgrading. This is a lot of documentation, but worth it in the long run.

### CF CLI

The upgrade to cf-release v233 led to acceptance test failure, as it requires CF CLI version 6.16+. We upgraded to this version in our cf-cli and cf-acceptance-tests Docker containers, which confounded the tests of other developers when merged. Upgrades to CF CLI versions can be tested using your own private containers while in development. Perhaps we should think about versioning our docker images so that we can pin particular versions in the pipeline to match the CF & BOSH versions being deployed.

### Acceptance Test Failures

The upgrade to v233 has introduced some new tests in the acceptance-test suite, which do not appear to be quite ready for the prime-time yet.

We experienced failures in:

* `routing` suite - The `multiple_app_ports` test fails if  `users_can_select_backend` is not set to `true` - The test receives a response of `CF-BackendSelectionNotAuthorized` which does not match the expected response of `CF-MultipleAppPortsMappedDiegoToDea` and causes the test to fail - This test should not be run unless the user is permitted to switch backends. We raised an issue with Pivotal for this test :
https://www.pivotaltracker.com/story/show/117685687
https://github.com/cloudfoundry/cf-acceptance-tests/issues/104

* `v3` suite - The `task_test` is being run even though we have the `cf-feature-flag` for `task_creation` set to `false` - The suite attempts to create a task and receives a response saying `Feature Disabled: task_creation` which does not cause any kind of failure - it then goes on to attempt to delete the task which fails as it receives and empty response to it's delete attempt, when it is expecting to receive a response indicating that the task is in a `FAILED` state
